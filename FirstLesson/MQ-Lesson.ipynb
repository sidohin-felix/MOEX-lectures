{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Message Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the idea of an MQ\n",
    "#\n",
    "# Standard scenario we all know: Send request -> Receive reply\n",
    "#\n",
    "# Less so standard scenario\n",
    "# \n",
    "# Send request -> periodically check for a reply for that request\n",
    "#\n",
    "# Even more not so standard\n",
    "#\n",
    "# Send request -> Read reply at some point from a stream\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The specific MQ implementation we will be learning is called ZeroMQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zmq\n",
    "import numpy\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Types of sockets: PUB, SUB, REQ, REP, DEALER, ROUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PUB = publisher, streams from socket\n",
    "#SUB = subscriber, listens to a publisher\n",
    "#REQ = Request\n",
    "#REP = Reply\n",
    "#DEALER = Non-blocking REQ socket\n",
    "#ROUTER = you don't need to worry about this one (commonly used for load balancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Hello\n",
      "1\n",
      "Hello\n",
      "2\n",
      "Hello\n",
      "3\n",
      "Hello\n",
      "4\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#A simple example\n",
    "import zmq\n",
    "# REQ - REP\n",
    "context = zmq.Context()\n",
    "rep_socket = context.socket(zmq.REP)\n",
    "rep_socket.bind(\"tcp://*:5002\")\n",
    "\n",
    "req_socket = context.socket(zmq.REQ)\n",
    "req_socket.connect(\"tcp://localhost:5002\")\n",
    "\n",
    "def sender(socket):\n",
    "    for i in range(0,5):\n",
    "        socket.send(str(i))\n",
    "        print(socket.recv())\n",
    "def receiver(socket):\n",
    "    while True:\n",
    "        print(socket.recv())\n",
    "        socket.send(\"Hello\")\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "p1 = Thread(target=receiver, args=(rep_socket,))\n",
    "p1.start()\n",
    "p2 = Thread(target=sender, args=(req_socket,))\n",
    "p2.start()\n",
    "#PUB - SUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DEALER - REP\n",
    "import zmq\n",
    "context = zmq.Context()\n",
    "rep_socket = context.socket(zmq.REP)\n",
    "rep_socket.bind(\"tcp://*:5003\")\n",
    "\n",
    "req_socket = context.socket(zmq.DEALER)\n",
    "req_socket.connect(\"tcp://localhost:5003\")\n",
    "\n",
    "def sender(socket):\n",
    "    for i in range(0,5):\n",
    "        socket.send(str(i))\n",
    "def receiver(socket):\n",
    "    while True:\n",
    "        print(socket.recv())\n",
    "        socket.send(\"Hello\")\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "p1 = Thread(target=receiver, args=(rep_socket,))\n",
    "p1.start()\n",
    "p2 = Thread(target=sender, args=(req_socket,))\n",
    "p2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why would you need this.\n",
    "\n",
    "# Broker's Feed -> ZMQ.PUB -> your application, the broker's functions are abstracted from application logic\n",
    "# therefore if let's say itInvest goes bankrupt, you won't really have to re-write your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So let's build a working example - let's call this robot (which is really just an application) RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Train a model on some data\n",
    "\n",
    "# Step 2: Save the model\n",
    "\n",
    "# Step 3: Application logic:\n",
    "\n",
    "# Receive market data -> feed feature vector into model -> receive prediction -> perform trade.\n",
    "\n",
    "#This to consider:\n",
    "# 1 - MaxPosition\n",
    "# 2 - Risk Management (i.e. how much money am I willing to lose today)\n",
    "\n",
    "# So let's review this:\n",
    "\n",
    "# RiskManagement Thread (REP)\n",
    "# Order placement Thread (REP)\n",
    "# Market Data Thread (PUB)\n",
    "# Strategy Thread (SUB, REQ)\n",
    "\n",
    "# Technically we could have unified the Startegy and RiskManagement Threads together, but for partical reasons\n",
    "# i.e. future code use, I decided it would be best to show you how to do this with separate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/models.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What is special about this world.\n",
    "\n",
    "#Well one of these things is that all these should work sort of independently. I.t. the risk manager and the strategy\n",
    "# thread communicate, but they also work concurrently due to the nature of their tasks.\n",
    "\n",
    "# The risk manager (RM) will close the position if your losses are triggered for example, while the Strategy thread\n",
    "# will ask it if it's possible to place an order of a certain size.\n",
    "\n",
    "# This is why Multi-threading/multi-processing is important - but due to the nature of these tasks, we're better off\n",
    "# working with MQs rather than Queues, stacks, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's train our model first.\n",
    "\n",
    "#I proposed a very very primitive idea - 5 classes:\n",
    "#Strong up (greater than 5), \n",
    "#Weak up (greather than 2), \n",
    "#Nothing (0), \n",
    "#Weak down (less than -2), \n",
    "#Strong down (less than -5)\n",
    "\n",
    "#The data that we have is not THAT useful, so we have to fix it so we have these classes.\n",
    "\n",
    "#Let's say for the sake of the argument that we are looking at SP500 over itself (sshhh don't tell anyone I have this\n",
    "# data!!!)\n",
    "\n",
    "#Step 1 - Features and targets\n",
    "\n",
    "\n",
    "#For simplicity's sake I want to looke at the deltaPrice, deltaSigmaPrice, and the\n",
    "#targets are as we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points for training: 1770\n",
      "Data points for testing : 759\n",
      "Total data points: 2529\n",
      "Feature information\n",
      "[ 0.24237824  0.26254858  0.24954985  0.24552334]\n",
      "Primitive Test\n",
      "=======================\n",
      "Predicted=[  0   0   0 -10 -10   0]| Factual=[5, 0, 0, -5, 10, -5]\n"
     ]
    }
   ],
   "source": [
    "#### Load data\n",
    "f = open('features.csv','r')\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "#Now let's deal a bit with it.\n",
    "del data[0]\n",
    "\n",
    "Xin = []\n",
    "yin = []\n",
    "#MAX = 104         -100 -50 0 50 100\n",
    "#MIN = -113\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    block = entry.split(',')\n",
    "    k = 0\n",
    "    v = []\n",
    "    for k in range(0,len(block)-1):\n",
    "        v.append(float(block[k]))\n",
    "    Xin.append(v)\n",
    "    #And now the rough classification:\n",
    "    t = float(block[-1].replace(\"\\r\\n\",\"\"))\n",
    "    if t > 10:\n",
    "        yin.append(10)\n",
    "    elif t > 5 and t < 10:\n",
    "        yin.append(5)\n",
    "    elif t < 5 and t > -5:\n",
    "        yin.append(0)\n",
    "    elif t > -10 and t < -5:\n",
    "        yin.append(-5)\n",
    "    elif t < -10:\n",
    "        yin.append(-10)\n",
    "\n",
    "#Let's say we'll take 70% of the data for training, 30% for testing.\n",
    "\n",
    "print(\"Data points for training: \" + str(int(len(Xin)*0.7)))\n",
    "print(\"Data points for testing : \" + str(len(Xin)- int(len(Xin)*0.7)))\n",
    "print(\"Total data points: \" + str(len(Xin)))\n",
    "\n",
    "X = numpy.asarray(Xin[:1770])\n",
    "y = numpy.asarray(yin[:1770])\n",
    "\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=100, max_features='auto', max_leaf_nodes=None,min_impurity_split=0,\n",
    "            min_samples_leaf=5, min_samples_split=4,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
    "clf.fit(X,y)\n",
    "print(\"Feature information\")\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print(\"Primitive Test\")\n",
    "print(\"=======================\")\n",
    "print(\"Predicted=\" + str(clf.predict(Xin[1772:1778])) + \"| Factual=\" + str(yin[1772:1778]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "10\n",
      "[-25,-10,0,10,25]\n",
      "[[ 0.33851552  0.03245904  0.15362436  0.05705652  0.41834457]]\n",
      "Precision: 0.309114927345\n"
     ]
    }
   ],
   "source": [
    "#Now let's save the model for later re-use\n",
    "with open('model.bin', 'wb') as output:\n",
    "    pickle.dump(clf,output,pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "#Well just for fun let me show you something you could use in your startegy later.\n",
    "print(clf.predict([Xin[1900]]))\n",
    "print(yin[1900])\n",
    "\n",
    "#The point is we can also look at this:\n",
    "print(\"[-25,-10,0,10,25]\")\n",
    "print(clf.predict_proba([Xin[1900]]))\n",
    "\n",
    "#We can also look at the overall precision/error-rate:\n",
    "y_predicted = clf.predict(Xin[1772:])\n",
    "good_guesses = 0\n",
    "bad_guesses = 0\n",
    "\n",
    "g_array = yin[1771:] - y_predicted\n",
    "\n",
    "for h in g_array:\n",
    "    if h == 0: good_guesses = good_guesses + 1\n",
    "    else: bad_guesses = bad_guesses + 1\n",
    "\n",
    "print(\"Precision: \" + str(float(good_guesses)/(bad_guesses + good_guesses)))\n",
    "        \n",
    "#Okay well it's a shitty model but still.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points for training: 1770\n",
      "Data points for testing : 759\n",
      "Total data points: 2529\n",
      "Feature information\n",
      "[ 0.22702869  0.29005152  0.24108769  0.24183211]\n",
      "Primitive Test\n",
      "=======================\n",
      "Predicted=[-13.90728 -15.84512  -9.99314  -9.42304 -18.21322  -9.73744]| Factual=[5.82, -1.62, -3.12, -6.24, 12.89, -9.61]\n"
     ]
    }
   ],
   "source": [
    "#We can always try a different approach - instead of a classifier we can use regression...\n",
    "#### Load data\n",
    "f = open('features.csv','r')\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "#Now let's deal a bit with it.\n",
    "del data[0]\n",
    "\n",
    "Xin = []\n",
    "yin = []\n",
    "#MAX = 104         -100 -50 0 50 100\n",
    "#MIN = -113\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    block = entry.split(',')\n",
    "    k = 0\n",
    "    v = []\n",
    "    for k in range(0,len(block)-1):\n",
    "        v.append(float(block[k]))\n",
    "    Xin.append(v)\n",
    "    #And now the rough classification:\n",
    "    t = float(block[-1].replace(\"\\r\\n\",\"\"))\n",
    "    yin.append(t)\n",
    "\n",
    "#Let's say we'll take 70% of the data for training, 30% for testing.\n",
    "\n",
    "print(\"Data points for training: \" + str(int(len(Xin)*0.7)))\n",
    "print(\"Data points for testing : \" + str(len(Xin)- int(len(Xin)*0.7)))\n",
    "print(\"Total data points: \" + str(len(Xin)))\n",
    "\n",
    "X = numpy.asarray(Xin[:1770])\n",
    "y = numpy.asarray(yin[:1770])\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=500, criterion='mse', max_depth=None, \n",
    "                            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                            max_features='auto', max_leaf_nodes=None, \n",
    "                            min_impurity_split=0.0, bootstrap=True, oob_score=True, n_jobs=1, \n",
    "                            random_state=None, verbose=0, warm_start=False)\n",
    "clf.fit(X,y)\n",
    "print(\"Feature information\")\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print(\"Primitive Test\")\n",
    "print(\"=======================\")\n",
    "print(\"Predicted=\" + str(clf.predict(Xin[1772:1778])) + \"| Factual=\" + str(yin[1772:1778]))\n",
    "\n",
    "#With a regression model it becomes very hard to say what is good and what is bad.\n",
    "# I will explain why.\n",
    "\n",
    "# For example the model says that the value will be -9, the factual is -12\n",
    "# That's not necessarily wrong, whereas predicted 0 factual -20 is probably wrong\n",
    "# This is why because regression and classifiers are slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points for training: 1770\n",
      "Data points for testing : 759\n",
      "Total data points: 2529\n",
      "Feature information\n",
      "New: [ 0.23783342  0.25264858  0.26307523  0.24644277]\n",
      "Old: [ 0.24237824  0.26254858  0.24954985  0.24552334]\n",
      "Precision: 0.403162055336\n"
     ]
    }
   ],
   "source": [
    "#Attempts at improving models.\n",
    "\n",
    "# A very common problem - trending data.\n",
    "# THERE ARE MANY WAYS TO DE-TREND (i.e. baseline analysis, randomization, FFT)\n",
    "# We will look at randomization.\n",
    "\n",
    "# Different sampling.\n",
    "#### Load data\n",
    "f = open('features.csv','r')\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "#Now let's deal a bit with it.\n",
    "del data[0]\n",
    "\n",
    "Xin = []\n",
    "yin = []\n",
    "#MAX = 104         -100 -50 0 50 100\n",
    "#MIN = -113\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    block = entry.split(',')\n",
    "    k = 0\n",
    "    v = []\n",
    "    for k in range(0,len(block)-1):\n",
    "        v.append(float(block[k]))\n",
    "    Xin.append(v)\n",
    "    #And now the rough classification:\n",
    "    t = float(block[-1].replace(\"\\r\\n\",\"\"))\n",
    "    if t > 10:\n",
    "        yin.append(10)\n",
    "    elif t > 5 and t < 10:\n",
    "        yin.append(5)\n",
    "    elif t < 5 and t > -5:\n",
    "        yin.append(0)\n",
    "    elif t > -10 and t < -5:\n",
    "        yin.append(-5)\n",
    "    elif t < -10:\n",
    "        yin.append(-10)\n",
    "\n",
    "#Let's say we'll take 70% of the data for training, 30% for testing.\n",
    "\n",
    "print(\"Data points for training: \" + str(int(len(Xin)*0.7)))\n",
    "trainSize = int(len(Xin)*0.7)\n",
    "print(\"Data points for testing : \" + str(len(Xin)- int(len(Xin)*0.7)))\n",
    "testSize = len(Xin)- int(len(Xin)*0.7)\n",
    "print(\"Total data points: \" + str(len(Xin)))\n",
    "\n",
    "#This is the only part which will change.\n",
    "\n",
    "Xinprime = []\n",
    "yinprime = []\n",
    "indices = []\n",
    "\n",
    "Xtest = []\n",
    "ytest = []\n",
    "#Select some random indexes:\n",
    "\n",
    "import random\n",
    "while(len(Xinprime) < trainSize):\n",
    "    index = random.randint(0, len(yin)-1)\n",
    "    if index in indices: \n",
    "        continue\n",
    "    else:\n",
    "        indices.append(index)\n",
    "        Xinprime.append(Xin[index])\n",
    "        yinprime.append(yin[index])\n",
    "\n",
    "        \n",
    "while(len(Xtest) < testSize/3):\n",
    "    index = random.randint(0, len(yin)-1)\n",
    "    if index in indices: \n",
    "        continue\n",
    "    else:\n",
    "        indices.append(index)\n",
    "        Xtest.append(Xin[index])\n",
    "        ytest.append(yin[index])\n",
    "    \n",
    "    \n",
    "X = numpy.asarray(Xinprime)\n",
    "y = numpy.asarray(yinprime)\n",
    "\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=100, max_features='auto', max_leaf_nodes=None,min_impurity_split=0,\n",
    "            min_samples_leaf=5, min_samples_split=4,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
    "clf.fit(X,y)\n",
    "print(\"Feature information\")\n",
    "print(\"New: \" + str(clf.feature_importances_))\n",
    "#Is this really a boost?\n",
    "print(\"Old: [ 0.24237824  0.26254858  0.24954985  0.24552334]\")\n",
    "\n",
    "#print(\"Primitive Test\")\n",
    "#print(\"=======================\")\n",
    "#print(\"Predicted=\" + str(clf.predict(numpy.asarray(Xtest))) + \"| Factual=\" + str(ytest))\n",
    "\n",
    "good_guesses = 0\n",
    "bad_guesses = 0\n",
    "\n",
    "g_array = numpy.asarray(ytest) - clf.predict(numpy.asarray(Xtest))\n",
    "\n",
    "for h in g_array:\n",
    "    if h == 0: good_guesses = good_guesses + 1\n",
    "    else: bad_guesses = bad_guesses + 1\n",
    "\n",
    "print(\"Precision: \" + str(float(good_guesses)/(bad_guesses + good_guesses)))\n",
    "\n",
    "#Very shitty.\n",
    "#The point is, you have to find good drivers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#And now the partical side.\n",
    "class marketDataReceiver:\n",
    "    \n",
    "    marketDataEndpoint = None\n",
    "    \n",
    "    def __init__(self,endpoint):\n",
    "        self.marketDataEndpoint = endpoint\n",
    "    \n",
    "    \n",
    "class robot:\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    def __init__(self,clf):\n",
    "        self.model = clf\n",
    "        \n",
    "    def predict(v):\n",
    "        return clf.predict([numpy.asarray(v)])\n",
    "    \n",
    "    \n",
    "class riskManager:\n",
    "    \n",
    "    maxPosition = 2\n",
    "    currentPosition = 0\n",
    "    maxLoss = 10000\n",
    "    blocked = False\n",
    "    \n",
    "    def placeMarketOrder(size):\n",
    "        if(not blocked):\n",
    "            if (abs(currentPosition + size) <= maxPosition):\n",
    "                #place the order\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def checkLoss():\n",
    "        #To be implemented\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#And now the coup de grace, putting it all together.\n",
    "# Problem 1: How do we share MD with robot?\n",
    "# Option 1: Use a Queue - a little ugly, because if you have multiple robot reading it, it causes problem\n",
    "# Option 2: Use a PUB/SUB proxy approach\n",
    "# SUB -> PUB -> SUB \n",
    "# Comes with its own drawback i.e. you'll probably have to understand the difference between TCP,UDP,IPC,INPROC,\n",
    "# PGM transports, measure latencies, and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
