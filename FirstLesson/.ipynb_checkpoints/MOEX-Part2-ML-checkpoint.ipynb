{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#So first, let me show you how to prepare the ugly data from last time.\n",
    "f = open('datasets/bank-full.csv','r') # 'r' = read.\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['management', 'technician', 'entrepreneur', 'blue-collar', 'unknown', 'retired', 'admin.', 'services', 'self-employed', 'unemployed', 'housemaid', 'student']\n"
     ]
    }
   ],
   "source": [
    "#Remove the header just to make sure.\n",
    "del data[0]\n",
    "\n",
    "job = []\n",
    "martial = []\n",
    "education = []\n",
    "default = []\n",
    "housing = []\n",
    "loan = []\n",
    "contact = []\n",
    "month = []\n",
    "poutcome = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for x in data:\n",
    "    x = x.replace(\"\\n\",\"\")\n",
    "    x = x.replace(\"\\\"\",\"\")\n",
    "    element = x.split(\";\")\n",
    "    if element[1] not in job: job.append(element[1])\n",
    "    if element[2] not in martial: martial.append(element[2])\n",
    "    if element[3] not in education: education.append(element[3])\n",
    "    if element[4] not in default: default.append(element[4])\n",
    "    if element[6] not in housing: housing.append(element[6])\n",
    "    if element[7] not in loan: loan.append(element[7])\n",
    "    if element[8] not in contact: contact.append(element[8])\n",
    "    if element[10] not in month: month.append(element[10])\n",
    "    if element[15] not in poutcome: poutcome.append(element[15])\n",
    "    if element[16] not in y : y.append(element[16])\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'management': 0, 'retired': 5, 'self-employed': 8, 'unknown': 4, 'unemployed': 9, 'housemaid': 10, 'admin.': 6, 'entrepreneur': 2, 'services': 7, 'student': 11, 'technician': 1, 'blue-collar': 3}\n",
      "{'single': 1, 'married': 0, 'divorced': 2}\n",
      "{'unknown': 2, 'primary': 3, 'tertiary': 0, 'secondary': 1}\n",
      "{'yes': 1, 'no': 0}\n",
      "{'yes': 0, 'no': 1}\n",
      "{'yes': 1, 'no': 0}\n",
      "{'unknown': 0, 'telephone': 2, 'cellular': 1}\n",
      "{'mar': 3, 'sep': 9, 'may': 5, 'jun': 6, 'jul': 7, 'nov': 11, 'feb': 2, 'aug': 8, 'jan': 1, 'apr': 4, 'dec': 12, 'oct': 10}\n",
      "{'unknown': 0, 'other': 2, 'success': 3, 'failure': 1}\n",
      "{'yes': 1, 'no': 0}\n"
     ]
    }
   ],
   "source": [
    "job_dict = {}\n",
    "i = 0\n",
    "for element in job:\n",
    "    job_dict[element] = i\n",
    "    i = i + 1\n",
    "print(job_dict)\n",
    "\n",
    "\n",
    "martial_dict = {}\n",
    "i = 0\n",
    "for element in martial:\n",
    "    martial_dict[element] = i\n",
    "    i = i + 1\n",
    "print(martial_dict)\n",
    "\n",
    "education_dict = {}\n",
    "i = 0\n",
    "for element in education:\n",
    "    education_dict[element] = i\n",
    "    i = i + 1\n",
    "print(education_dict)\n",
    "\n",
    "default_dict = {}\n",
    "i = 0\n",
    "for element in default:\n",
    "    default_dict[element] = i\n",
    "    i = i + 1\n",
    "print(default_dict)\n",
    "\n",
    "housing_dict = {}\n",
    "i = 0\n",
    "for element in housing:\n",
    "    housing_dict[element] = i\n",
    "    i = i + 1\n",
    "print(housing_dict)\n",
    "\n",
    "loan_dict = {}\n",
    "i = 0\n",
    "for element in loan:\n",
    "    loan_dict[element] = i\n",
    "    i = i + 1\n",
    "print(loan_dict)\n",
    "\n",
    "contact_dict = {}\n",
    "i = 0\n",
    "for element in contact:\n",
    "    contact_dict[element] = i\n",
    "    i = i + 1\n",
    "print(contact_dict)\n",
    "\n",
    "\n",
    "month_dict = {\n",
    "    \"jan\":1,\n",
    "    \"feb\":2,\n",
    "    \"mar\":3,\n",
    "    \"apr\":4,\n",
    "    \"may\":5,\n",
    "    \"jun\":6,\n",
    "    \"jul\":7,\n",
    "    \"aug\":8,\n",
    "    \"sep\":9,\n",
    "    \"oct\":10,\n",
    "    \"nov\":11,\n",
    "    \"dec\":12\n",
    "}\n",
    "\n",
    "print(month_dict)\n",
    "\n",
    "poutcome_dict = {}\n",
    "i = 0\n",
    "for element in poutcome:\n",
    "    poutcome_dict[element] = i\n",
    "    i = i + 1\n",
    "print(poutcome_dict)\n",
    "\n",
    "y_dict = {}\n",
    "i = 0\n",
    "for element in y:\n",
    "    y_dict[element] = i\n",
    "    i = i + 1\n",
    "print(y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 0, 0, 0, 0, 0, 0, 0, 5, 261, 1, -1, 0, -1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Now let's play\n",
    "f = open('datasets/bank-full.csv','r') # 'r' = read.\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "del data[0]\n",
    "\n",
    "#Now we're going \n",
    "good_data = []\n",
    "\n",
    "for x in data:\n",
    "    x = x.replace(\"\\n\",\"\")\n",
    "    x = x.replace(\"\\\"\",\"\")\n",
    "    element = x.split(\";\")\n",
    "    vector = []\n",
    "    vector.append(int(element[0]))\n",
    "    vector.append(int(job_dict[element[1]]))\n",
    "    vector.append(int(martial_dict[element[2]]))\n",
    "    vector.append(int(education_dict[element[3]]))\n",
    "    vector.append(int(default_dict[element[4]]))\n",
    "    vector.append(int(housing_dict[element[6]]))\n",
    "    vector.append(int(loan_dict[element[7]]))\n",
    "    vector.append(int(contact_dict[element[8]]))\n",
    "    vector.append(int(month_dict[element[10]]))\n",
    "    vector.append(int(element[11]))\n",
    "    vector.append(int(element[12]))\n",
    "    vector.append(int(element[13]))\n",
    "    vector.append(int(element[14]))\n",
    "    vector.append(int(element[13]))\n",
    "    vector.append(int(element[14]))\n",
    "    vector.append(int(poutcome_dict[element[15]]))\n",
    "    vector.append(int(y_dict[element[16]]))\n",
    "    good_data.append(vector)\n",
    "\n",
    "print(good_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 10]\n",
      "[ 6  8 10]\n"
     ]
    }
   ],
   "source": [
    "#The truth is to do ML we need to use NumPy\n",
    "#What is NumPy = Numerical Python\n",
    "#A wrapper on top of Python which uses C libraries in order to optimize.\n",
    "import numpy\n",
    "\n",
    "a = [1,2,3] \n",
    "b = [5,6,7]\n",
    "\n",
    "c = []\n",
    "\n",
    "for i in range(0,len(a)):\n",
    "    c.append(a[i] + b[i])\n",
    "\n",
    "    \n",
    "    \n",
    "print(c)\n",
    "\n",
    "a1 = numpy.asarray(a)\n",
    "b1 = numpy.asarray(b)\n",
    "\n",
    "c = a1 + b1\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "ml_data = []\n",
    "target = []\n",
    "\n",
    "for x in data:\n",
    "    x = x.replace(\"\\n\",\"\")\n",
    "    x = x.replace(\"\\\"\",\"\")\n",
    "    element = x.split(\";\")\n",
    "    vector = numpy.array([])\n",
    "    vector = numpy.append(vector,int(element[0]))\n",
    "    vector = numpy.append(vector,int(job_dict[element[1]]))\n",
    "    vector = numpy.append(vector,int(martial_dict[element[2]]))\n",
    "    vector = numpy.append(vector,int(education_dict[element[3]]))\n",
    "    vector = numpy.append(vector,int(default_dict[element[4]]))\n",
    "    vector = numpy.append(vector,int(housing_dict[element[6]]))\n",
    "    vector = numpy.append(vector,int(loan_dict[element[7]]))\n",
    "    vector = numpy.append(vector,int(contact_dict[element[8]]))\n",
    "    vector = numpy.append(vector,int(month_dict[element[10]]))\n",
    "    vector = numpy.append(vector,int(element[11]))\n",
    "    vector = numpy.append(vector,int(element[12]))\n",
    "    vector = numpy.append(vector,int(element[13]))\n",
    "    vector = numpy.append(vector,int(element[14]))\n",
    "    vector = numpy.append(vector,int(element[13]))\n",
    "    vector = numpy.append(vector,int(element[14]))\n",
    "    vector = numpy.append(vector,int(poutcome_dict[element[15]]))\n",
    "    target.append(int(y_dict[element[16]]))\n",
    "    ml_data.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  58.    0.    0. ...,   -1.    0.    0.]\n",
      " [  44.    1.    1. ...,   -1.    0.    0.]\n",
      " [  33.    2.    0. ...,   -1.    0.    0.]\n",
      " ..., \n",
      " [  72.    5.    0. ...,  184.    3.    3.]\n",
      " [  57.    3.    0. ...,   -1.    0.    0.]\n",
      " [  37.    2.    0. ...,  188.   11.    2.]]\n",
      "[0 0 0 ..., 1 0 0]\n",
      "45211\n",
      "[[  58.    0.    0. ...,   -1.    0.    0.]\n",
      " [  44.    1.    1. ...,   -1.    0.    0.]\n",
      " [  33.    2.    0. ...,   -1.    0.    0.]\n",
      " ..., \n",
      " [  54.    6.    2. ...,   -1.    0.    0.]\n",
      " [  34.    0.    0. ...,   90.    7.    2.]\n",
      " [  38.    1.    0. ...,  119.    1.    1.]]\n",
      "[0 0 0 ..., 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# [1,2,7,0,0,0,1] -> 0\n",
    "# [2,3,4,6,7,8,1] -> 1\n",
    "\n",
    "\n",
    "# X = INPUT\n",
    "# y = \n",
    "\n",
    "X = numpy.asarray(ml_data)\n",
    "y = numpy.asarray(target)\n",
    "#And this can really be used with ML!\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print(len(X))\n",
    "print(X[0:40000])\n",
    "print(y[0:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0911636   0.04114924  0.01832172  0.0203525   0.00110703  0.02555347\n",
      "  0.00637308  0.02086352  0.09343023  0.58510129  0.03441677  0.01596175\n",
      "  0.00607381  0.01728551  0.00576043  0.01708604]\n",
      "[0]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#The SciKit Python Library\n",
    "#Method 1: Random Forest\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#A very basic way\n",
    "#clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "#clf.fit(X[0:40000], y[0:40000])\n",
    "#print(clf.feature_importances_)\n",
    "#\n",
    "#t = clf.predict(X[40005])\n",
    "#print(t)\n",
    "#print(y[40005])\n",
    "#\n",
    "#t = clf.predict(X[40010])\n",
    "#print(t)\n",
    "#print(y[40010])\n",
    "\n",
    "#[  9.51661036e-02   9.39077776e-03   3.50659852e-03   3.95663828e-02\n",
    "#   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.81928579e-03\n",
    "#   2.15026504e-01   3.99341357e-01   8.31933769e-05   0.00000000e+00\n",
    "#   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.33099797e-01]\n",
    "\n",
    "#A more complex way\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=20, max_features='auto', max_leaf_nodes=None,min_impurity_split=0,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "clf.fit(X[0:40000], y[0:40000])\n",
    "pickle.dump(clf,open( \"model.dat\", \"wb\" ))\n",
    "print(clf.feature_importances_)\n",
    "t = clf.predict(X[40005])\n",
    "print(t)\n",
    "print(y[40005])\n",
    "\n",
    "t = clf.predict(X[40010])\n",
    "print(t)\n",
    "print(y[40010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0911636   0.04114924  0.01832172  0.0203525   0.00110703  0.02555347\n",
      "  0.00637308  0.02086352  0.09343023  0.58510129  0.03441677  0.01596175\n",
      "  0.00607381  0.01728551  0.00576043  0.01708604]\n"
     ]
    }
   ],
   "source": [
    "#So what exactly is this data?, well these are the correlations these things have to the outcome...\n",
    "# Neural network!\n",
    "\n",
    "clf2 = pickle.load(open(\"model.dat\", \"rb\" ) )\n",
    "print(clf2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "1\n",
      "[0]\n",
      "0\n",
      "[0]\n",
      "1\n",
      "[0]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)                         \n",
    "clf.fit(X[0:40000], y[0:40000])\n",
    "t = clf.predict(X[40005])\n",
    "print(t)\n",
    "print(y[40005])\n",
    "\n",
    "t = clf.predict(X[40010])\n",
    "print(t)\n",
    "print(y[40010])\n",
    "\n",
    "clf = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "epsilon=1e-08, hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "warm_start=False)\n",
    "clf.fit(X[0:40000], y[0:40000])\n",
    "t = clf.predict(X[40005])\n",
    "print(t)\n",
    "print(y[40005])\n",
    "\n",
    "t = clf.predict(X[40010])\n",
    "print(t)\n",
    "print(y[40010])\n",
    "\n",
    "#clf.predict()\n",
    "\n",
    "\n",
    "#Data - Training/Test\n",
    "# Model -> Training\n",
    "# Validation = M(Test) #Success/ M(Test) #Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "1\n",
      "[0]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/felixsidokhine/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X[0:40000], y[0:40000])\n",
    "t = clf.predict(X[40005])\n",
    "print(t)\n",
    "print(y[40005])\n",
    "\n",
    "t = clf.predict(X[40010])\n",
    "print(t)\n",
    "print(y[40010])\n",
    "\n",
    "#[deltaBR,sigmaBR,deltaSi,sigmaSi] [0] 0 = drop price, 1 = Si raise price \n",
    "#[sigma, rolling sigma, ma, delta levelone, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  42.    2.    2. ...,   -1.    0.    0.]\n",
      " [  58.    5.    0. ...,   -1.    0.    0.]\n",
      " [  41.    6.    2. ...,   -1.    0.    0.]\n",
      " ..., \n",
      " [  51.    1.    0. ...,   -1.    0.    0.]\n",
      " [  71.    5.    2. ...,   -1.    0.    0.]\n",
      " [  72.    5.    0. ...,  184.    3.    3.]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(decision_function_shape='ovo')\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we explain about train/test and we move on to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we move onto a more complicated library SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "arr = numpy.array([[1, 2],[3, 4]])\n",
    "\n",
    "linalg.det(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = numpy.arange(9).reshape((3, 3)) + numpy.diag([1, 0, 1])\n",
    "uarr, spec, vharr = linalg.svd(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1617463  -0.98659196  0.02178164]\n",
      " [-0.47456365  0.09711667  0.87484724]\n",
      " [-0.86523261  0.13116653 -0.48390895]]\n"
     ]
    }
   ],
   "source": [
    "print(uarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basically SciPy is also a wrapper on top of C/C++/Fortran libraries which speeds up operations.\n",
    "#Here's a small diagram:\n",
    "\n",
    "# Case 1: Purely Python\n",
    "\n",
    "# you build an average function in python, since python isn't strongly-typed it will always infer the type of data\n",
    "# hence being slower.\n",
    "\n",
    "# i.e. data -> function -> evaluate -> return value.\n",
    "\n",
    "#Since this is sub-optimal for many cases the way to do it is:\n",
    "\n",
    "# Python Application - Wrapper - C++ Library (.so/.dll/.whatever on mac OS)\n",
    "# Hence you are invoking a function defined in the library and its being executed inside that library, NOT by python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And now we get to one more fun part you can do with Python - Threads, Queue, etc..\n",
    "# Why? Multi-threading.\n",
    "\n",
    "# Why multi-threading?\n",
    "\n",
    "# function(m) -> response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.5\n",
      "\n",
      "\n",
      "12.0\n",
      "\n",
      "14.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Basic way of doing it.\n",
    "import numpy\n",
    "import threading\n",
    "\n",
    "def worker(data):\n",
    "    x = numpy.asarray(data)\n",
    "    print(str(numpy.average(x)) + \"\\n\")\n",
    "    return numpy.average(x)\n",
    "\n",
    "#Let's look assume we have 4 array:\n",
    "arr = [[1,2,3,4,5],[4,5,6,7],[7,10,12,19],[15,6,1,6,1,35,67,9,0,1]]\n",
    "\n",
    "for block in arr:\n",
    "    t = threading.Thread(target=worker,args=(block,))\n",
    "    t.start()\n",
    "    #t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Okay not very interesting, but now assume you had data coming in which could be worked on in parallel, so\n",
    "#how do we deal with it.\n",
    "\n",
    "import Queue\n",
    "import numpy\n",
    "import threading\n",
    "q = Queue.Queue()\n",
    "\n",
    "#The Queue object is Thread-safe.\n",
    "def worker():\n",
    "    while(not q.empty()):\n",
    "        x = numpy.asarray(q.get())\n",
    "        print(str(numpy.average(x)) + \"\\n\")\n",
    "        return numpy.average(x)\n",
    "\n",
    "#Let's look assume we have 4 array:\n",
    "arr = [[1,2,3,4,5],[4,5,6,7],[7,10,12,19],[15,6,1,6,1,35,67,9,0,1]]\n",
    "\n",
    "for block in arr:\n",
    "    q.put(block)\n",
    "    \n",
    "#What the hell?\n",
    "for i in range(0,2):\n",
    "    t = threading.Thread(target=worker)\n",
    "    t.start()\n",
    "\n",
    "\n",
    "#Right because we have a return!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "[3.0, 5.5, 12.0, 14.1]\n",
      "\n",
      "5.5\n",
      "\n",
      "12.0\n",
      "\n",
      "14.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Queue\n",
    "import numpy\n",
    "import threading\n",
    "q = Queue.Queue()\n",
    "out = []\n",
    "\n",
    "#The Queue object is Thread-safe.\n",
    "def worker():\n",
    "    while(not q.empty()):\n",
    "        x = numpy.asarray(q.get())\n",
    "        print(str(numpy.average(x)) + \"\\n\")\n",
    "        out.append(numpy.average(x))\n",
    "\n",
    "#Let's look assume we have 4 array:\n",
    "arr = [[1,2,3,4,5],[4,5,6,7],[7,10,12,19],[15,6,1,6,1,35,67,9,0,1]]\n",
    "\n",
    "for block in arr:\n",
    "    q.put(block)\n",
    "    \n",
    "for i in range(0,2):\n",
    "    t = threading.Thread(target=worker)\n",
    "    t.start()\n",
    "\n",
    "#The problem here remains that technically we asked out before we were done! - technically this is OK for MT, I will\n",
    "#explain why.\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 5.5, 12.0, 14.1]\n"
     ]
    }
   ],
   "source": [
    "#Here's what in \"out\" after all threads have completed.\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The producer-cosumer model.\n",
    "\n",
    "# I will produce - you will consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Message Queues.\n",
    "\n",
    "#Since all of you want to trade, here's the big secret: ZeroMQ\n",
    "\n",
    "# What is a message queue? Well a lot of things, but the best way to describe it would be to say it's a post-office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Why? Well several reasons.\n",
    "# 1) Publishing of data without hipster gayness like WebSockets - which are slow, unreliable and for the \"Web\"\n",
    "# 2) Because you may need to connect many applications together\n",
    "# 3) Non-blocking mechansims (notably DEALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First there existed a context\n",
    "\n",
    "context = zmq.Context(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then a socket\n",
    "pub = context.socket(zmq.PUB)\n",
    "#bind\n",
    "pub.bind(\"tcp://*:1080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#And now publish away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What you should understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) ZMQ is a great way to get \"around\" horrible threading issues\n",
    "#2) ZMQ will let you build distributed application - BUT! You will have to implement much of the logic yourself\n",
    "#3) ZMQ is powerful - sometimes too powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MQ vs Threads - not exactly the issue.\n",
    "# MQ can be used in intra-thread communication (instead of a Queue for example, BUT a little different and you\n",
    "# will have to come up with some way of handling that)\n",
    "# MQ is more to \"scale-out\" across hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A very basic concept.\n",
    "\n",
    "# Worker Applications - listen to MQ for jobs - Dispatcher and Map-Reduce.\n",
    "\n",
    "# Publisher creates a task and keeps sending the jobs up for grabs\n",
    "# workers also publish jobs they have taken to avoid a worker taking a job already picked up\n",
    "# publisher removes jobs which are complete\n",
    "# once all jobs are complete, the publisher does some final calculations and closes the task.\n",
    "\n",
    "# is this reliable?\n",
    "# well yes and no - in practice you could have workers picking up same jobs, due to latency\n",
    "# therefore in practice you would use mod n\n",
    "# And there you go! You wrote your own computing cluster!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
